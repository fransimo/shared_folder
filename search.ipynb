{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compact-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import telnetlib\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def connect(host=\"\",user=\"\",password=\"\"):\n",
    "    tn = telnetlib.Telnet(host,4000)\n",
    "    tn.read_until(b\">\")\n",
    "\n",
    "    if password != \"\":\n",
    "        s = \"auth \" + user + \" \" + password + \"\\n\"\n",
    "        tn.write(bytes(s,'ascii'))\n",
    "        r = tn_wait(tn)\n",
    "        print(r.decode('ascii'))   \n",
    "\n",
    "    return tn\n",
    "\n",
    "def tn_wait(tn):\n",
    "    r = ''\n",
    "    t = 0\n",
    "    while len(r) < 2 and t < 10:\n",
    "        r = tn.read_very_eager()\n",
    "        time.sleep(1)\n",
    "        t=t+1\n",
    "    return r\n",
    "\n",
    "def save_downloaded(already_downloaded):\n",
    "    with open('already_downloaded.json', 'w',encoding=\"ascii\", newline='\\r\\n') as outfile:\n",
    "        json.dump(already_downloaded, outfile, indent=2, ensure_ascii=False)\n",
    "\n",
    "def read_downloaded():\n",
    "    already_downloaded = []\n",
    "    with open('already_downloaded.json') as json_file:\n",
    "        already_downloaded = json.load(json_file)\n",
    "    return already_downloaded\n",
    "\n",
    "def add_downloaded(new_download):\n",
    "    already_downloaded = read_downloaded()\n",
    "    already_downloaded = already_downloaded + new_download\n",
    "    already_downloaded = list(set(already_downloaded))\n",
    "    already_downloaded.sort()\n",
    "    save_downloaded(already_downloaded)\n",
    "    \n",
    "def check_downloaded(i):\n",
    "    already_downloaded = read_downloaded()\n",
    "    if i.find(b\"ed2k\")>0:\n",
    "        b = i.split(b\":\")[2].decode('ascii')\n",
    "        if b in already_downloaded:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def choose_download(r):\n",
    "    # TODO: filter by filename length (optionally)\n",
    "    r_clean = [i for i in r.splitlines() if i.find(b\"ed2k\")>0]\n",
    "    return [int(i[i.find(b\"m[\")+2:i.find(b\"]\")]) for i in r_clean if not(check_downloaded(i))]\n",
    "\n",
    "def donwload_resuts(tn,r,max_download=0):\n",
    "    new_download = [i.split(b\":\")[2].decode('ascii') for i in r.split() if i.find(b\"ed2k\")>0]\n",
    "    res = choose_download(r)\n",
    "    c=0\n",
    "    for i in res:\n",
    "        d = \"d %d\\n\" % i\n",
    "        tn.write(bytes(d,'ascii'))\n",
    "        r = tn_wait(tn)\n",
    "        # print(r.decode('ascii'))\n",
    "        c = c + 1\n",
    "        if max_download>0 and max_download<=c:\n",
    "            pass\n",
    "    add_downloaded(new_download)\n",
    "\n",
    "def single_search(tn, search,max_download=0):\n",
    "    tn.write(bytes(search,'ascii'))\n",
    "    r = tn_wait(tn)\n",
    "    #print(r.decode('ascii'))\n",
    "\n",
    "    time.sleep(30)\n",
    "\n",
    "    tn.write(bytes(\"vr\\n\",'ascii'))\n",
    "    r = tn_wait(tn)\n",
    "    #print(r.decode('ascii'))\n",
    "\n",
    "    if r[0:70].decode('ascii').find(\"\\n0 results\") == -1:\n",
    "        # print(r[0:70].decode('ascii')[0:70])\n",
    "        donwload_resuts(tn,r,max_download)\n",
    "        \n",
    "    \n",
    "def pattern_search(tn, pattern,init_sq,end_sq,max_download=0):\n",
    "    for j in range(init_sq,end_sq):\n",
    "        print(j)\n",
    "        search = pattern % j\n",
    "        single_search(tn,search,max_download)  \n",
    "        \n",
    "def raw_search(ext):\n",
    "    for e in ext.split(' '):\n",
    "        print(e)\n",
    "        single_search(tn,\"s DSC {}\\n\".format(e))\n",
    "        single_search(tn,\"s IMG {}\\n\".format(e))\n",
    "        \n",
    "def cancel_pattern(tn,pattern):\n",
    "    tn.write(bytes(\"vd\\n\",'ascii'))\n",
    "    r = tn_wait(tn)\n",
    "    jpgs = [int(i[i.find(b\"m[\")+3:i.find(b\"]\")]) for i in r.splitlines() if i.find(pattern)>0]\n",
    "    s = \"cancel\"\n",
    "    for j in jpgs:\n",
    "        s = s + \" \" + str(j)\n",
    "    s = s + \" \\n\"\n",
    "    tn.write(bytes(s,'ascii'))\n",
    "    r = tn_wait(tn)\n",
    "    tn.write(bytes(\"confirm yes\\n\",'ascii'))\n",
    "    r = tn_wait(tn)\n",
    "    \n",
    "   \n",
    "\n",
    "host = \"192.168.2.35\"\n",
    "user = \"admin\"\n",
    "password = \"\"\n",
    "\n",
    "t_init = datetime.now()\n",
    "\n",
    "tn = connect(host,user,password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-arrest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-butter",
   "metadata": {},
   "source": [
    "# RAWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "right-warehouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".3fr\n",
      ".ari\n",
      ".arw\n",
      ".srf\n",
      ".sr2\n",
      ".bay\n",
      ".braw\n",
      ".cri\n",
      ".crw\n",
      ".cr2\n",
      ".cr3\n",
      ".cap\n",
      ".iiq\n",
      ".eip\n",
      ".dcs\n",
      ".dcr\n",
      ".drf\n",
      ".k25\n",
      ".kdc\n",
      ".dng\n",
      ".erf\n",
      ".fff\n",
      ".gpr\n",
      ".mef\n",
      ".mdc\n",
      ".mos\n",
      ".mrw\n",
      ".nef\n",
      ".nrw\n",
      ".orf\n",
      ".pef\n",
      ".ptx\n",
      ".pxn\n",
      ".R3D\n",
      ".raf\n",
      ".raw\n",
      ".rw2\n",
      ".raw\n",
      ".rwl\n",
      ".dng\n",
      ".rwz\n",
      ".srw\n",
      ".x3f\n"
     ]
    }
   ],
   "source": [
    "raw_search('.3fr') # (Hasselblad)\n",
    "raw_search('.ari') # (Arri Alexa)\n",
    "raw_search('.arw .srf .sr2') # (Sony)\n",
    "raw_search('.bay') # (Casio)\n",
    "raw_search('.braw') # (Blackmagic Design)\n",
    "raw_search('.cri') # (Cintel)\n",
    "raw_search('.crw .cr2 .cr3') # (Canon)\n",
    "raw_search('.cap .iiq .eip') # (Phase_One)\n",
    "raw_search('.dcs .dcr .drf .k25 .kdc') # (Kodak)\n",
    "raw_search('.dng') # (Adobe)\n",
    "raw_search('.erf') # (Epson)\n",
    "raw_search('.fff') # (Imacon/Hasselblad raw)\n",
    "raw_search('.gpr') # (GoPro)\n",
    "raw_search('.mef') # (Mamiya)\n",
    "raw_search('.mdc') # (Minolta, Agfa)\n",
    "raw_search('.mos') # (Leaf)\n",
    "raw_search('.mrw') # (Minolta, Konica Minolta)\n",
    "raw_search('.nef .nrw') # (Nikon)\n",
    "raw_search('.orf') # (Olympus)\n",
    "raw_search('.pef .ptx') # (Pentax)\n",
    "raw_search('.pxn') # (Logitech)\n",
    "raw_search('.R3D') # (RED Digital Cinema)\n",
    "raw_search('.raf') # (Fuji)\n",
    "raw_search('.raw .rw2') # (Panasonic)\n",
    "raw_search('.raw .rwl .dng') # (Leica)\n",
    "raw_search('.rwz') # (Rawzor)\n",
    "raw_search('.srw') # (Samsung)\n",
    "raw_search('.x3f') # (Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-speech",
   "metadata": {},
   "source": [
    "# CVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "banner-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_search(tn,'s CV DOCX\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intimate-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_search(tn,'s Curriculum DOCX\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-ethnic",
   "metadata": {},
   "source": [
    "# .JPG pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "simplified-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern_search(tn,\"s IMG_%04d.JPG -minsize 1500000 -maxsize 15000000 \\n\",1,9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "round-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_search(tn,'s IMG 2501 JPG -minsize 1500000 -maxsize 15000000 \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-campaign",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "configured-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancel_pattern(tn,b'jpg')  \n",
    "cancel_pattern(tn,b'oraya')  \n",
    "cancel_pattern(tn,b'.avi')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-rover",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stylish-juvenile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=3145, microseconds=111955)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_end = datetime.now()\n",
    "\n",
    "\n",
    "t_exec = (t_end - t_init)\n",
    "t_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "center-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_search(tn,'s bianca pose\\n') # :( mierda!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lightweight-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancel_pattern(tn,b'jpg')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-destruction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-expert",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
